{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.profilers import SimpleProfiler  # Updated for Lightning 2.0\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Set seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.deterministic = False  # For deterministic results\n",
    "torch.backends.cudnn.benchmark = True  # Disabling to ensure deterministic algorithm\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')  # Optimize matmulÂ precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data Module and Dataset Definition\n",
    "\n",
    "class DepressionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.texts[index])\n",
    "        label = self.labels[index]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class DepressionDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, df, tokenizer, max_length=128, batch_size=16):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Split the dataset into training and validation sets (80/20 split)\n",
    "        train_df, val_df = train_test_split(\n",
    "            self.df, test_size=0.2, random_state=42, stratify=self.df['label']\n",
    "        )\n",
    "        self.train_dataset = DepressionDataset(\n",
    "            train_df['body'].tolist(), train_df['label'].tolist(), self.tokenizer, self.max_length\n",
    "        )\n",
    "        self.val_dataset = DepressionDataset(\n",
    "            val_df['body'].tolist(), val_df['label'].tolist(), self.tokenizer, self.max_length\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Model Definition\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "\n",
    "class DepressionClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes, steps_per_epoch=None, n_epochs=None, lr=2e-5):\n",
    "        super().__init__()\n",
    "        # Use DistilRoBERTa for faster training\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained('distilroberta-base', num_labels=n_classes).train()\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        # Separate accuracy metrics for training and validation\n",
    "        self.train_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "        self.val_acc = Accuracy(task=\"multiclass\", num_classes=n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.train_acc.update(preds, batch['labels'])\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Compute and print training accuracy for the epoch\n",
    "        train_epoch_acc = self.train_acc.compute()\n",
    "        print(f\"Epoch {self.current_epoch} - Training Accuracy: {train_epoch_acc:.4f}\")\n",
    "        self.train_acc.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(\n",
    "            input_ids=batch['input_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_acc.update(preds, batch['labels'])\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Compute and print validation accuracy for the epoch\n",
    "        val_epoch_acc = self.val_acc.compute()\n",
    "        print(f\"Epoch {self.current_epoch} - Validation Accuracy: {val_epoch_acc:.4f}\")\n",
    "        self.val_acc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        if self.steps_per_epoch is None or self.n_epochs is None:\n",
    "            return optimizer\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    "        )\n",
    "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9453/2559523744.py:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('reddit_depression_dataset.csv')  # CSV should have \"text\" and \"label\" columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2470778, 8)\n",
      "Dataset shape after dropping NaNs: (2009643, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                             | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | model     | RobertaForSequenceClassification | 82.1 M | train\n",
      "1 | train_acc | MulticlassAccuracy               | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy               | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "82.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.1 M    Total params\n",
      "328.480   Total estimated model params size (MB)\n",
      "124       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff3a2977ab64e1494085222e7c982bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Validation Accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0880128b6a54dc9837dd6529483efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818e111954ae452c871bdee46b078648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Validation Accuracy: 0.9487\n",
      "Epoch 0 - Training Accuracy: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  590522         \t|  3170.4         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  3166.3         \t|  1              \t|  3166.3         \t|  99.868         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.15243        \t|  12561          \t|  1914.7         \t|  60.392         \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  0.07954        \t|  12561          \t|  999.1          \t|  31.513         \t|\n",
      "|  [LightningModule]DepressionClassifier.optimizer_step                                                                                                                 \t|  0.079321       \t|  12561          \t|  996.35         \t|  31.426         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.069331       \t|  12561          \t|  870.87         \t|  27.468         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.065165       \t|  3143           \t|  204.81         \t|  6.4601         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.0077447      \t|  12561          \t|  97.281         \t|  3.0684         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.0019979      \t|  12561          \t|  25.095         \t|  0.79154        \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.0016599      \t|  3143           \t|  5.2169         \t|  0.16455        \t|\n",
      "|  [LightningModule]DepressionClassifier.optimizer_zero_grad                                                                                                            \t|  0.00030919     \t|  12561          \t|  3.8838         \t|  0.1225         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.00024094     \t|  15704          \t|  3.7838         \t|  0.11935        \t|\n",
      "|  [LightningModule]DepressionClassifier.transfer_batch_to_device                                                                                                       \t|  0.00019932     \t|  15704          \t|  3.1301         \t|  0.098729       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  1.5596         \t|  1              \t|  1.5596         \t|  0.049192       \t|\n",
      "|  save_checkpoint                                                                                                                                                      \t|  1.5543         \t|  1              \t|  1.5543         \t|  0.049023       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.00044453     \t|  3143           \t|  1.3972         \t|  0.044069       \t|\n",
      "|  [LightningDataModule]DepressionDataModule.setup                                                                                                                      \t|  0.71183        \t|  1              \t|  0.71183        \t|  0.022452       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  1.9092e-05     \t|  12561          \t|  0.23981        \t|  0.007564       \t|\n",
      "|  [LightningModule]DepressionClassifier.configure_gradient_clipping                                                                                                    \t|  1.8512e-05     \t|  12561          \t|  0.23254        \t|  0.0073345      \t|\n",
      "|  [LightningModule]DepressionClassifier.lr_scheduler_step                                                                                                              \t|  1.123e-05      \t|  12561          \t|  0.14106        \t|  0.0044491      \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  3.789e-06      \t|  12561          \t|  0.047594       \t|  0.0015012      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_after_backward                                                                                      \t|  2.4015e-06     \t|  12561          \t|  0.030165       \t|  0.00095143     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  1.8622e-06     \t|  12561          \t|  0.023391       \t|  0.00073777     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.022807       \t|  1              \t|  0.022807       \t|  0.00071938     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  1.6148e-06     \t|  12561          \t|  0.020284       \t|  0.00063978     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  1.5133e-06     \t|  12561          \t|  0.019008       \t|  0.00059954     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_before_batch_transfer                                                                                                       \t|  9.3832e-07     \t|  15704          \t|  0.014735       \t|  0.00046477     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_after_batch_transfer                                                                                                        \t|  8.2292e-07     \t|  15704          \t|  0.012923       \t|  0.00040761     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_backward                                                                                     \t|  1.0008e-06     \t|  12561          \t|  0.012572       \t|  0.00039652     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.0058247      \t|  2              \t|  0.011649       \t|  0.00036744     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  9.038e-07      \t|  12561          \t|  0.011353       \t|  0.00035808     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_batch_end                                                                                                             \t|  8.8279e-07     \t|  12561          \t|  0.011089       \t|  0.00034975     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_before_zero_grad                                                                                                            \t|  7.6943e-07     \t|  12561          \t|  0.0096648      \t|  0.00030484     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.0093735      \t|  1              \t|  0.0093735      \t|  0.00029565     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  6.7476e-07     \t|  12561          \t|  0.0084757      \t|  0.00026733     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_batch_start                                                                                                           \t|  6.6962e-07     \t|  12561          \t|  0.0084111      \t|  0.0002653      \t|\n",
      "|  [LightningModule]DepressionClassifier.on_after_backward                                                                                                              \t|  6.6188e-07     \t|  12561          \t|  0.0083139      \t|  0.00026223     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  6.3649e-07     \t|  12561          \t|  0.007995       \t|  0.00025217     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  6.2239e-07     \t|  12561          \t|  0.0078179      \t|  0.00024659     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  6.0415e-07     \t|  12561          \t|  0.0075887      \t|  0.00023936     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  5.6789e-07     \t|  12561          \t|  0.0071333      \t|  0.00022499     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_before_backward                                                                                                             \t|  5.622e-07      \t|  12561          \t|  0.0070618      \t|  0.00022274     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  2.2438e-06     \t|  3143           \t|  0.0070523      \t|  0.00022244     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  5.5199e-07     \t|  12561          \t|  0.0069335      \t|  0.00021869     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  5.3772e-07     \t|  12561          \t|  0.0067543      \t|  0.00021304     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  2.1167e-06     \t|  3143           \t|  0.0066528      \t|  0.00020984     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  5.0734e-07     \t|  12561          \t|  0.0063726      \t|  0.000201       \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  5.0068e-07     \t|  12561          \t|  0.006289       \t|  0.00019836     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  4.9683e-07     \t|  12561          \t|  0.0062407      \t|  0.00019684     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  1.9618e-06     \t|  3143           \t|  0.0061658      \t|  0.00019448     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  4.8492e-07     \t|  12561          \t|  0.0060911      \t|  0.00019212     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  4.7521e-07     \t|  12561          \t|  0.0059691      \t|  0.00018827     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  4.5542e-07     \t|  12561          \t|  0.0057206      \t|  0.00018043     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  4.2481e-07     \t|  12561          \t|  0.005336       \t|  0.0001683      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  4.2198e-07     \t|  12561          \t|  0.0053005      \t|  0.00016718     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_before_optimizer_step                                                                                                       \t|  4.0381e-07     \t|  12561          \t|  0.0050723      \t|  0.00015999     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  3.8422e-07     \t|  12561          \t|  0.0048262      \t|  0.00015222     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.0045064      \t|  1              \t|  0.0045064      \t|  0.00014214     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  1.3449e-06     \t|  3143           \t|  0.004227       \t|  0.00013332     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_epoch_end                                                                                                        \t|  0.0018498      \t|  2              \t|  0.0036996      \t|  0.00011669     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_batch_end                                                                                                        \t|  7.068e-07      \t|  3143           \t|  0.0022215      \t|  7.0068e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  6.5303e-07     \t|  3143           \t|  0.0020525      \t|  6.4738e-05     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_batch_start                                                                                                      \t|  6.1995e-07     \t|  3143           \t|  0.0019485      \t|  6.1458e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  5.9759e-07     \t|  3143           \t|  0.0018782      \t|  5.9242e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.00092521     \t|  2              \t|  0.0018504      \t|  5.8365e-05     \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.0015442      \t|  1              \t|  0.0015442      \t|  4.8707e-05     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_model_eval                                                                                                       \t|  0.0007674      \t|  2              \t|  0.0015348      \t|  4.841e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  4.4047e-07     \t|  3143           \t|  0.0013844      \t|  4.3666e-05     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_epoch_end                                                                                                             \t|  0.00059184     \t|  1              \t|  0.00059184     \t|  1.8667e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.0005784      \t|  1              \t|  0.0005784      \t|  1.8244e-05     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_model_zero_grad                                                                                                  \t|  0.00055248     \t|  1              \t|  0.00055248     \t|  1.7426e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.00046281     \t|  1              \t|  0.00046281     \t|  1.4598e-05     \t|\n",
      "|  [LightningModule]DepressionClassifier.configure_optimizers                                                                                                           \t|  0.00040648     \t|  1              \t|  0.00040648     \t|  1.2821e-05     \t|\n",
      "|  [LightningDataModule]DepressionDataModule.train_dataloader                                                                                                           \t|  0.00024882     \t|  1              \t|  0.00024882     \t|  7.848e-06      \t|\n",
      "|  [LightningDataModule]DepressionDataModule.val_dataloader                                                                                                             \t|  0.00012985     \t|  1              \t|  0.00012985     \t|  4.0957e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.00012914     \t|  1              \t|  0.00012914     \t|  4.0731e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  8.422e-05      \t|  1              \t|  8.422e-05      \t|  2.6564e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  3.5568e-05     \t|  2              \t|  7.1136e-05     \t|  2.2437e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_start                                                                                         \t|  1.5026e-05     \t|  1              \t|  1.5026e-05     \t|  4.7394e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.setup                                                                                                  \t|  1.0903e-05     \t|  1              \t|  1.0903e-05     \t|  3.439e-07      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_end                                                                                      \t|  5.384e-06      \t|  2              \t|  1.0768e-05     \t|  3.3964e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_start                                                                                    \t|  5.0225e-06     \t|  2              \t|  1.0045e-05     \t|  3.1683e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  8.728e-06      \t|  1              \t|  8.728e-06      \t|  2.7529e-07     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_start                                                                                                            \t|  3.892e-06      \t|  2              \t|  7.784e-06      \t|  2.4552e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  3.777e-06      \t|  2              \t|  7.554e-06      \t|  2.3826e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  3.7535e-06     \t|  2              \t|  7.507e-06      \t|  2.3678e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  6.842e-06      \t|  1              \t|  6.842e-06      \t|  2.1581e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_end                                                                                             \t|  6.71e-06       \t|  1              \t|  6.71e-06       \t|  2.1164e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  4.863e-06      \t|  1              \t|  4.863e-06      \t|  1.5339e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  2.2985e-06     \t|  2              \t|  4.597e-06      \t|  1.45e-07       \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_epoch_start                                                                                                           \t|  3.854e-06      \t|  1              \t|  3.854e-06      \t|  1.2156e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  3.846e-06      \t|  1              \t|  3.846e-06      \t|  1.2131e-07     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_start                                                                                                                 \t|  3.832e-06      \t|  1              \t|  3.832e-06      \t|  1.2087e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  1.779e-06      \t|  2              \t|  3.558e-06      \t|  1.1222e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  3.357e-06      \t|  1              \t|  3.357e-06      \t|  1.0588e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  1.5605e-06     \t|  2              \t|  3.121e-06      \t|  9.8441e-08     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  2.968e-06      \t|  1              \t|  2.968e-06      \t|  9.3615e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  1.271e-06      \t|  2              \t|  2.542e-06      \t|  8.0178e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  2.514e-06      \t|  1              \t|  2.514e-06      \t|  7.9295e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  2.383e-06      \t|  1              \t|  2.383e-06      \t|  7.5163e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  2.237e-06      \t|  1              \t|  2.237e-06      \t|  7.0558e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_end                                                                                           \t|  2.092e-06      \t|  1              \t|  2.092e-06      \t|  6.5985e-08     \t|\n",
      "|  [LightningDataModule]DepressionDataModule.teardown                                                                                                                   \t|  2.033e-06      \t|  1              \t|  2.033e-06      \t|  6.4124e-08     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  1.989e-06      \t|  1              \t|  1.989e-06      \t|  6.2736e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  9.935e-07      \t|  2              \t|  1.987e-06      \t|  6.2673e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  9.64e-07       \t|  2              \t|  1.928e-06      \t|  6.0812e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.teardown                                                                                               \t|  1.902e-06      \t|  1              \t|  1.902e-06      \t|  5.9992e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.configure_callbacks                                                                                                            \t|  1.885e-06      \t|  1              \t|  1.885e-06      \t|  5.9455e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  1.801e-06      \t|  1              \t|  1.801e-06      \t|  5.6806e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  1.675e-06      \t|  1              \t|  1.675e-06      \t|  5.2832e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.teardown                                                                                                                       \t|  1.48e-06       \t|  1              \t|  1.48e-06       \t|  4.6681e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_fit_end                                                                                                                     \t|  1.475e-06      \t|  1              \t|  1.475e-06      \t|  4.6524e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_start                                                                                           \t|  1.454e-06      \t|  1              \t|  1.454e-06      \t|  4.5861e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  1.446e-06      \t|  1              \t|  1.446e-06      \t|  4.5609e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_end                                                                                                              \t|  7.19e-07       \t|  2              \t|  1.438e-06      \t|  4.5356e-08     \t|\n",
      "|  [LightningDataModule]DepressionDataModule.state_dict                                                                                                                 \t|  1.426e-06      \t|  1              \t|  1.426e-06      \t|  4.4978e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  1.409e-06      \t|  1              \t|  1.409e-06      \t|  4.4442e-08     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  1.292e-06      \t|  1              \t|  1.292e-06      \t|  4.0751e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  1.279e-06      \t|  1              \t|  1.279e-06      \t|  4.0341e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  6.165e-07      \t|  2              \t|  1.233e-06      \t|  3.8891e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  6.01e-07       \t|  2              \t|  1.202e-06      \t|  3.7913e-08     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  1.118e-06      \t|  1              \t|  1.118e-06      \t|  3.5263e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.setup                                                                                                                          \t|  1.089e-06      \t|  1              \t|  1.089e-06      \t|  3.4349e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_validation_epoch_start                                                                                                      \t|  5.125e-07      \t|  2              \t|  1.025e-06      \t|  3.233e-08      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  1.005e-06      \t|  1              \t|  1.005e-06      \t|  3.1699e-08     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  9.93e-07       \t|  1              \t|  9.93e-07       \t|  3.1321e-08     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  4.955e-07      \t|  2              \t|  9.91e-07       \t|  3.1257e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  4.815e-07      \t|  2              \t|  9.63e-07       \t|  3.0374e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  9.52e-07       \t|  1              \t|  9.52e-07       \t|  3.0027e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  9.04e-07       \t|  1              \t|  9.04e-07       \t|  2.8513e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  8.84e-07       \t|  1              \t|  8.84e-07       \t|  2.7883e-08     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  4.15e-07       \t|  2              \t|  8.3e-07        \t|  2.6179e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_train_end                                                                                                                   \t|  7.96e-07       \t|  1              \t|  7.96e-07       \t|  2.5107e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  7.67e-07       \t|  1              \t|  7.67e-07       \t|  2.4192e-08     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  7.16e-07       \t|  1              \t|  7.16e-07       \t|  2.2584e-08     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  7.06e-07       \t|  1              \t|  7.06e-07       \t|  2.2268e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_fit_start                                                                                                                   \t|  6.53e-07       \t|  1              \t|  6.53e-07       \t|  2.0597e-08     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  6.33e-07       \t|  1              \t|  6.33e-07       \t|  1.9966e-08     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  6.16e-07       \t|  1              \t|  6.16e-07       \t|  1.9429e-08     \t|\n",
      "|  [LightningModule]DepressionClassifier.on_save_checkpoint                                                                                                             \t|  5.27e-07       \t|  1              \t|  5.27e-07       \t|  1.6622e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  5.23e-07       \t|  1              \t|  5.23e-07       \t|  1.6496e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  5.21e-07       \t|  1              \t|  5.21e-07       \t|  1.6433e-08     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  4.83e-07       \t|  1              \t|  4.83e-07       \t|  1.5234e-08     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  4.04e-07       \t|  1              \t|  4.04e-07       \t|  1.2743e-08     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Training Setup and Execution\n",
    "\n",
    "# Load your dataset (update the path to your CSV file)\n",
    "df = pd.read_csv('reddit_depression_dataset.csv')  # CSV should have \"text\" and \"label\" columns\n",
    "\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "\n",
    "# Drop rows where 'text' or 'label' contains NaN values\n",
    "df = df.dropna(subset=['body', 'label'])\n",
    "print(\"Dataset shape after dropping NaNs:\", df.shape)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Create the DataModule\n",
    "data_module = DepressionDataModule(df, tokenizer, max_length=128, batch_size=128)\n",
    "data_module.setup()\n",
    "\n",
    "# Calculate steps per epoch (for learning rate scheduling)\n",
    "steps_per_epoch = len(data_module.train_dataloader())\n",
    "n_epochs = 1  # Adjust the number of epochs as needed\n",
    "\n",
    "# Create the LightningModule model (ensure n_classes matches your dataset)\n",
    "n_classes = df['label'].nunique()\n",
    "model = DepressionClassifier(n_classes=n_classes, steps_per_epoch=steps_per_epoch, n_epochs=n_epochs, lr=2e-5)\n",
    "\n",
    "# Set up callbacks for early stopping and checkpointing\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=3, verbose=True, mode='min')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints_new',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Setup the profiler (using SimpleProfiler for Lightning 2.0)\n",
    "profiler = SimpleProfiler(dirpath='profiler_logs')\n",
    "\n",
    "# Configure the Trainer for Lightning 2.0 (using mixed precision for speed and memory efficiency)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=n_epochs,\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    profiler=profiler,\n",
    "    precision=\"bf16-mixed\",\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Start training using the DataModule\n",
    "trainer.fit(model, datamodule=data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23323/3974494690.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('reddit_depression_dataset.csv') # CSV should have \"text\" and \"label\" columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (2470778, 8)\n",
      "Dataset shape after dropping NaNs: (2009643, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                             | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | model     | RobertaForSequenceClassification | 82.1 M | train\n",
      "1 | train_acc | MulticlassAccuracy               | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy               | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "82.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.1 M    Total params\n",
      "328.480   Total estimated model params size (MB)\n",
      "124       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c35640cd9a549e69b01e9be9af38cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Validation Accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2098b1ef1af54132b1444796da87305b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714d167735714c3fa10e582fc5b7d91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Validation Accuracy: 0.9510\n",
      "Epoch 0 - Training Accuracy: 0.9499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# Resume Training\n",
    "\n",
    "df = pd.read_csv('reddit_depression_dataset.csv') # CSV should have \"text\" and \"label\" columns\n",
    "\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "\n",
    "# Drop rows where 'text' or 'label' contains NaN values\n",
    "df = df.dropna(subset=['body', 'label'])\n",
    "print(\"Dataset shape after dropping NaNs:\", df.shape)\n",
    "\n",
    "# Initialize the tokenizer (make sure it matches the one used during training)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Create the DataModule\n",
    "data_module = DepressionDataModule(df, tokenizer, max_length=128, batch_size=128)\n",
    "data_module.setup()\n",
    "\n",
    "# Specify the checkpoint path (update if necessary)\n",
    "checkpoint_path = \"checkpoints_new/best-checkpoint.ckpt\"\n",
    "\n",
    "# Resume model training from checkpoint\n",
    "# Make sure to pass in any necessary parameters that your model's __init__ requires\n",
    "model = DepressionClassifier.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    n_classes=df['label'].nunique(),\n",
    "    steps_per_epoch=len(data_module.train_dataloader()),\n",
    "    n_epochs=1,  # or the total epochs you plan to train for\n",
    "    lr=2e-5\n",
    ")\n",
    "\n",
    "# Setup callbacks (reinitialize if needed)\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', patience=3, verbose=True, mode='min')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Configure the Trainer (ensure settings match your available GPU and desired precision)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,  # Adjust total epochs as needed; training will resume from the checkpoint's epoch\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback],\n",
    "    precision=\"bf16-mixed\",  # Mixed precision for efficiency\n",
    "    log_every_n_steps=10,\n",
    "    enable_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Resume training\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load Best Model and Save\n",
    "\n",
    "# Get the path to the best checkpoint\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "print(\"Best model saved at:\", best_model_path)\n",
    "\n",
    "# Load the best model from checkpoint\n",
    "best_model = DepressionClassifier(2).load_from_checkpoint(best_model_path)\n",
    "\n",
    "# Optionally, save the best model to a desired location (e.g., a .pt file)\n",
    "torch.save(best_model.state_dict(), \"best_depression_classifier.pt\")\n",
    "print(\"Best model state_dict saved to best_depression_classifier.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Not Depressed\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2  # e.g., binary classification: 0 = Not Depressed, 1 = Depressed\n",
    "\n",
    "# Specify the path to your checkpoint file\n",
    "checkpoint_path = \"checkpoints_new/best-checkpoint.ckpt\"\n",
    "\n",
    "# Load the model from the checkpoint. Pass any necessary parameters expected by your model's __init__\n",
    "model = DepressionClassifier.load_from_checkpoint(checkpoint_path, n_classes=n_classes)\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize the tokenizer (ensure it matches the one used during training)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('distilroberta-base')\n",
    "\n",
    "def predict(text):\n",
    "    # Tokenize the input text and move tensors to the same device as the model\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Run the model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    prediction = torch.argmax(logits, dim=1).item()\n",
    "    return \"Depressed\" if prediction == 1 else \"Not Depressed\"\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"I feel happy and am looking forward to tommorrow\"\n",
    "print(\"Prediction:\", predict(sample_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
